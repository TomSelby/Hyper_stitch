{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320e5cf7-bc4a-4f13-9d1a-7c4eae772d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import hyperspy.api as hs\n",
    "import kornia.feature as KF\n",
    "import kornia as K\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from kornia_moons.viz import *\n",
    "from kornia_moons.feature import *\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357e5bb9-a2f9-4245-958b-5a8d2ff530d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "feature = KF.KeyNetAffNetHardNet(5000, True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdfae8d-07f9-4a2b-be18-a7c240757e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch_tensor(npy):\n",
    "    npy = npy - np.amin(npy)\n",
    "    npy = 255*(npy/np.amax(npy))\n",
    "    tensor = np.zeros((1,1,np.shape(npy)[0],np.shape(npy)[1]))\n",
    "    tensor[0,0] = npy\n",
    "    tensor = torch.FloatTensor(tensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba4cda1-2a50-4552-9ae3-4c4f39e02331",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = numpy_to_torch_tensor(np.load(r\"C:\\Users\\tas72\\Documents\\PhD\\dg606\\20230624\\Stitching_and_corr\\test\\20230624_100334_vbf.npy\"))\n",
    "img1 = numpy_to_torch_tensor(np.load(r\"C:\\Users\\tas72\\Documents\\PhD\\dg606\\20230624\\Stitching_and_corr\\test\\20230624_100824_vbf.npy\"))\n",
    "input_dict = {\"image0\":img0,\n",
    "             \"image1\":img1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fea08dd-a971-4eae-a938-46800a03666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = KF.KeyNetAffNetHardNet(5000, True).eval().to(device)\n",
    "adalam_config = {\"device\": device}\n",
    "hw1 = torch.tensor(img1.shape[2:])\n",
    "hw2 = torch.tensor(img1.shape[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91f0c94-d819-47a0-bfa4-30c009c814ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    lafs1, resps1, descs1 = feature(img0)\n",
    "    lafs2, resps2, descs2 = feature(img1)\n",
    "    dists, idxs = KF.match_adalam(\n",
    "        descs1.squeeze(0),\n",
    "        descs2.squeeze(0),\n",
    "        lafs1,\n",
    "        lafs2,  # Adalam takes into account also geometric information\n",
    "        config=adalam_config,\n",
    "        hw1=hw1,\n",
    "        hw2=hw2,  # Adalam also benefits from knowing image size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b8193a-7039-45c7-ac92-2b9e615a2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461 tentative matches with AdaLAM\n"
     ]
    }
   ],
   "source": [
    "print(f\"{idxs.shape[0]} tentative matches with AdaLAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d90f9a6d-3081-4196-9e18-ebfbfa5f060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_keypoints(lafs1, lafs2, idxs):\n",
    "    mkpts1 = KF.get_laf_center(lafs1).squeeze()[idxs[:, 0]].detach().cpu().numpy()\n",
    "    mkpts2 = KF.get_laf_center(lafs2).squeeze()[idxs[:, 1]].detach().cpu().numpy()\n",
    "    return mkpts1, mkpts2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab659c98-a2fd-4b15-ac0c-90506d898f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 inliers with AdaLAM\n"
     ]
    }
   ],
   "source": [
    "mkpts1, mkpts2 = get_matching_keypoints(lafs1, lafs2, idxs)\n",
    "\n",
    "Fm, inliers = cv2.findFundamentalMat(mkpts1, mkpts2, cv2.USAC_MAGSAC, 0.75, 0.999, 100000)\n",
    "inliers = inliers > 0\n",
    "print(f\"{inliers.sum()} inliers with AdaLAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "422480e9-fb99-4bb1-957b-e1d6765ebf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tm,inliners = cv2.estimateAffinePartial2D(mkpts1,mkpts2,confidence= 0.999,ransacReprojThreshold=0.99,refineIters=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e3d05f8-2986-4754-948b-9d350a2c4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 inliers with AdaLAM\n"
     ]
    }
   ],
   "source": [
    "print(f\"{inliers.sum()} inliers with AdaLAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba148c62-7533-4a1e-b5f1-960d72b175f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00043958e+00,  6.00119099e-04, -3.84868873e+01],\n",
       "       [-6.00119099e-04,  1.00043958e+00,  3.28275265e+02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea1df22-e359-4cc0-8e05-58e5ce851cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_LAF_matches(\n",
    "    lafs1,\n",
    "    lafs2,\n",
    "    idxs,\n",
    "    K.tensor_to_image(img0),\n",
    "    K.tensor_to_image(img1),\n",
    "    inliers,\n",
    "    draw_dict={\"inlier_color\": (0.2, 1, 0.2), \"tentative_color\": (1, 1, 0.2, 0.3), \"feature_color\": None, \"vertical\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "864739b2-a2bf-4983-8cda-37e784e839a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.98204032e-09, -6.10998475e-05, -1.25948367e-03],\n",
       "       [ 6.16093288e-05,  5.60208921e-07, -1.66586067e-02],\n",
       "       [-1.89629048e-02,  1.39584277e-02,  5.41887185e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ccf40-0b8f-4636-8619-6ea3d0e03e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
